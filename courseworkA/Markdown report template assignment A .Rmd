---
title: "Report coursework assignment A - 2021"
subtitle: "CS4125 Seminar Research Methodology for Data Science"
author: "Nikki Bouman (4597648), Anuj Singh (), Gwennan Smitskamp ()"
date: "20/04/2021"
output:
   pdf_document:
      fig_caption: true
      number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


\tableofcontents


# Part 1 - Design and set-up of true experiment 


## The motivation for the planned research
<!-- (Max 250 words) -->
The recent outbreak of the COVID-19 pandemic has changed our daily lives significantly. People are obligated to stay at home, disrupting their usual social interactions in both work and private life. The situation compels people to meet online. Typically, in such digital interactions, interlocutors can see each other by means of webcam streaming. However, this may not always be the case. Some or all interlocutors may not be visible during online dialogue, which could affect the quality of the conversation and the mutual understanding.

An important effect of the shift from face-to-face to online interaction can be revealed by studying laughter, as it is extremely contagious social behavior (Provine, 1992). Humans are very prone to unintentionally or unconsciously laugh as a social signal in any form; from a minor smile to laughing out loud. Additionally, laughing is one of the most important social signals for lubricating the flow of social interaction (Griffin et al., 2015).


## The theory underlying the research  
<!-- (Max 250 words) Preferable based on theories reported in literature -->
The effect of visibility on the use of gestures as a communicative function has been studied broadly (Alibali, Heath, & Myers, 2001; J. B. Bavelas, Chovil, Lawrie, & Wade, 1992; Cohen & Harrison, 1973; Cohen, 1977; Emmorey & Casey, 2001; Krauss, Dushay, Chen, & Rauscher, 1995; RimÂ´e, 1982). , J. Bavelas, Gerwing, Sutton, and Prevost (2008) provide a summary of previous experiments where rate and form of gestures were compared under two conditions: where the addressee could see the speaker and where the addressee could not see the speaker. These experiments show that speakers gestured at higher rate when they communicated with mutual visibility than without. J. Bavelas et al. (2008) extended these experiments by focusing on both visibility and dialogue as a variable, finding similar results. Furthermore, they found that speakers gestured at a significantly higher rate in a telephone dialogue than in a monologue to a tape recorder, confirming that visibility is not the only variable operating in telephone conversations. These experiments showed us that visibility plays a major role in the rate of gesturing, but that people also gesture when they are not visible to each other. As laughter can be seen as a form of gesturing, these findings are relevant for this study.

Laughing together is found to be essentially collaborative (Mehu & Dunbar, 2008; Coates, 2007). Joint laughter therefore serves important means to achieve effective team meetings (Ponton, Osbourne, Greenwood, & Thompson, 2018), considering that people who laugh on video are perceived with a higher likeability than people who do not (Reysen, 2006). This social function of joint laughter emphasises the relevance of studying the occurrence, now that the majority of meetings take place online.


## Research questions 
<!-- The research question that will be examined in the experiment (or alternatively the hypothesis that will be tested in the experiment) -->
We will aim to answer the following research question:

What is the effect of webcam visibility during online dialogue on the frequency and duration of joint laughter?

When recognizing laughter we do not focus on the reason why someone is laughing. We
consider anything from an awkward laugh in a moment of silence to laughing out loud about
a joke as a laughter episode regardless of the context. In order to guide the experiment to
answering the research question, the following sub-questions are considered:

1. To what extent does webcam visibility affect the frequency of joint laughter?

2. To what extent does webcam visibility affect the duration of joint laughter?

## The related conceptual model 

<!-- ![\label{cm}](img/A-1 conceptual model.png) -->
```{r pressure, echo=FALSE, fig.cap="The conceptual model to test the effect of mutual webcam visibility on joint laughter", out.width = '100%'}
knitr::include_graphics("img/A-1 conceptual model.png")
```


## Experimental Design 
One of the most important requirements for the setup of the experiment, was the creation of a comfortable and pleasant ambiance so that people would laugh. Therefore, it was decided that a game would comply, as the participants get the chance to interact with each other in a undemanding setting where the attention of the participants would be drawn to a task. It was reasoned that this would contribute to a reduction of awkwardness and give all the participants the option to speak and laugh. Additionally, the game needed to have a smooth flow that would automatically keep going to keep the interference of the researchers to a minimum. 

The game that was chosen is called 30 Seconds. During the game, participants work together in teams (in the case of the experiment: two teams of two people) and gain points by guessing what the team member is describing. These descriptions include concepts such as famous persons, locations, movies and brands. Every team gets 30 seconds to guess as many concepts on the card as possible. Who is describing and who is guessing switches after every card.



## Experimental procedure 
The experiment will be set up in an online setting in a Zoom meeting. The host, one of us (not visible), will be able to send private messages containing the five words, share their screen and sound for a 30 second timer, and turn the participants' webcams on and off.

The following will repeat for every card of five words:

1. The host sends the words to the participant who has the turn to describe.

2. The host starts the 30 second timer.

3. The participant will try to describe as many words as possible, while his/her teammate will try to guess the words.

4. The timer rings, the host puts the score in the chat.

During the experiment, multiple things will happen. Each time all players have guessed and described a card (i.e. after four cards total), their webcams will switch on or off. After each player has guessed and described four cards (i.e. after sixteen cards total), the final score will be displayed and the teams will be rearranged. The previous will then repeat until every participant has been in a team with every other participant.

## Measures
Describe the measure that will be used

## Participants
Describe which participants will recruit in the study and how they will be recruited

## Suggested statistical analyses
Describe the statistical test you suggest to care out on the collected data

<!-- # Part 2 - Generalized linear models -->

<!-- ## Question 1 Twitter sentiment analysis (Between groups - single factor)  -->

<!-- ### Conceptual model -->
<!-- Make a conceptual model for the following research question: Is there a difference in the sentiment of the tweets related to the different celebrities? -->

<!-- ### Collecting tweets, and data preparation -->
<!-- Include the annotated R script (excluding your personal Keys and Access Tokens information), but put echo=FALSE, so code is not included in the output pdf file. -->


<!-- ```{r, echo=FALSE, message=FALSE, warning=FALSE, include = FALSE} -->

<!-- #during writing you could add "eval = FALSE",  kntr will than not run this code chunk (take some time do) -->

<!-- #setwd("~/surfdrive/Teaching/own teaching/IN4125 - Seminar Research Methodology for Data Science/2019/coursework A")  -->
<!-- # commented this. Let's make this relative when trying to fix this file -->
<!-- # apple , note use / instead of \, which used by windows -->


<!-- #install.packages("twitteR", dependencies = TRUE) -->
<!-- library(twitteR) -->
<!-- #install.packages("RCurl", dependencies = T) -->
<!-- library(RCurl) -->
<!-- #install.packages("bitops", dependencies = T) -->
<!-- library(bitops) -->
<!-- #install.packages("plyr", dependencies = T) -->
<!-- library(plyr) -->
<!-- #install.packages('stringr', dependencies = T) -->
<!-- library(stringr) -->
<!-- #install.packages("NLP", dependencies = T) -->
<!-- library(NLP) -->
<!-- #install.packages("tm", dependencies = T) -->
<!-- library(tm) -->
<!-- #install.packages("wordcloud", dependencies=T) -->
<!-- #install.packages("RColorBrewer", dependencies=TRUE) -->
<!-- library(RColorBrewer) -->
<!-- library(wordcloud) -->
<!-- #install.packages("reshape", dependencies=T) -->
<!-- library(reshape) -->

<!-- ################### functions -->


<!-- clearTweets <- function(tweets, excl) { -->

<!--   tweets.text <- sapply(tweets, function(t)t$getText()) #get text out of tweets  -->


<!--   tweets.text = gsub('[[:cntrl:]]', '', tweets.text) -->
<!--   tweets.text = gsub('\\d+', '', tweets.text) -->
<!--   tweets.text <- str_replace_all(tweets.text,"[^[:graph:]]", " ") #remove graphic -->


<!--   corpus <- Corpus(VectorSource(tweets.text)) -->

<!--   corpus_clean <- tm_map(corpus, removePunctuation) -->
<!--   corpus_clean <- tm_map(corpus_clean, content_transformer(tolower)) -->
<!--   corpus_clean <- tm_map(corpus_clean, removeWords, stopwords("english")) -->
<!--   corpus_clean <- tm_map(corpus_clean, removeNumbers) -->
<!--   corpus_clean <- tm_map(corpus_clean, stripWhitespace) -->
<!--   corpus_clean <- tm_map(corpus_clean, removeWords, c(excl,"http","https","httpst")) -->


<!--   return(corpus_clean) -->
<!-- }  -->


<!-- ## capture all the output to a file. -->

<!-- ################# Collect from Twitter -->

<!-- # for creating a twitter app (apps.twitter.com) see youtube https://youtu.be/lT4Kosc_ers -->
<!-- #consumer_key <-'your key' -->
<!-- #consumer_scret <- 'your secret' -->
<!-- #access_token <- 'your access token' -->
<!-- #access_scret <- 'your access scret' -->

<!-- source("your_twitter.R") #this file will set my personal variables for my twitter app, adjust the name of this file. use the provide template your_twitter.R -->

<!-- setup_twitter_oauth(consumer_key,consumer_scret, access_token,access_scret) #connect to  twitter app -->


<!-- ##### This example uses the following 3 celebrities: Donald Trump, Hillary Clinton, and Bernie Sanders -->
<!-- ##  You should replace this with your own celebrities, at least 3, but more preferred  -->
<!-- ##  Note that it will take the computer some to collect the tweets -->

<!-- tweets_T <- searchTwitter("#trump", n=300, lang="en", resultType="recent") #300 recent tweets about Donald Trump, in English (I think that 1500 tweets is max) -->
<!-- tweets_C <- searchTwitter("#hillary", n=300, lang="en", resultType="recent") #300 recent tweets about Hillary Clinton -->
<!-- tweets_B <- searchTwitter("#bernie", n=300, lang="en", resultType="recent") #300 recent tweets about Bernie Sanders -->



<!-- ######################## WordCloud -->
<!-- ### This not requires in the assignment, but still fun to do  -->

<!-- # based on https://youtu.be/JoArGkOpeU0 -->

<!-- #corpus_T<-clearTweets(tweets_T, c("trump","amp","realdonaldtrump","trumptrain","donald","trumps","alwaystrump")) #remove also some campain slogans -->
<!-- #wordcloud(corpus_T, max.words=50) -->

<!-- #corpus_C<-clearTweets(tweets_C, c("hillary","amp","clinton","hillarys")) -->
<!-- #wordcloud(corpus_C,  max.words=50) -->

<!-- #corpus_B<-clearTweets(tweets_B, c("bernie", "amp", "sanders","bernies")) -->
<!-- #wordcloud(corpus_B,  max.words=50) -->
<!-- ############################## -->

<!-- ######################## Sentiment analysis -->

<!-- tweets_T.text <- laply(tweets_T, function(t)t$getText()) #get text out of tweets  -->
<!-- tweets_C.text <- laply(tweets_C, function(t)t$getText()) #get text out of tweets -->
<!-- tweets_B.text <- laply(tweets_B, function(t)t$getText()) #get text out of tweets -->



<!-- #taken from https://github.com/mjhea0/twitter-sentiment-analysis -->
<!-- pos <- scan('positive-words.txt', what = 'character', comment.char=';') #read the positive words -->
<!-- neg <- scan('negative-words.txt', what = 'character', comment.char=';') #read the negative words -->

<!-- source("sentiment3.R") #load algoritm -->
<!-- # see sentiment3.R form more information about sentiment analysis. It assigns a intereger score -->
<!-- # by substracitng the number of occurrence of negative words from that of positive words -->

<!-- analysis_T <- score.sentiment(tweets_T.text, pos, neg) -->
<!-- analysis_C <- score.sentiment(tweets_C.text, pos, neg) -->
<!-- analysis_B <- score.sentiment(tweets_B.text, pos, neg) -->


<!-- sem<-data.frame(analysis_T$score, analysis_C$score, analysis_B$score) -->


<!-- semFrame <-melt(sem, measured=c(analysis_T.score,analysis_C.score, analysis_B.score )) -->
<!-- names(semFrame) <- c("Candidate", "score") -->
<!-- semFrame$Candidate <-factor(semFrame$Candidate, labels=c("Donald Trump", "Hillary Clinton", "Bernie Sanders")) # change the labels for your celibrities -->

<!-- #The data you need for the analyses can be found in semFrame -->

<!-- ``` -->

<!-- ### Homogeneity of variance analysis -->
<!-- Analyze the homogeneity of variance of sentiments of the tweets of the different celebrities, and provide interpretation -->

<!-- ```{r} -->
<!-- #include your code and output in the document -->
<!-- ``` -->


<!-- ### Visual inspection Mean and distribution sentiments -->
<!-- Graphically examine the mean and distribution sentiments of tweets for each celebrity, and provide interpretation -->

<!-- ```{r} -->
<!-- #include your code and output in the document -->
<!-- ``` -->
<!-- ### Frequentist approach -->

<!-- #### Linear model -->
<!-- Use a linear model to analyze whether the knowledge to which celebrity a tweet relates has a significant impact on explaining the sentiments of the tweets. Provide interpretation of results  -->

<!-- ```{r} -->
<!-- #include your code and output in the document -->
<!-- ``` -->

<!-- #### Post Hoc analysis -->
<!-- If a model that includes the celebrity is better in explaining the sentiments of tweets than a model without such predictor, conduct a post-hoc analysis with e.g. Bonferroni correction, to examine which of celebrity tweets differ from the other celebrity tweets. Provide interpretation of the results -->

<!-- ```{r} -->
<!-- #include your code and output in the document -->
<!-- ``` -->

<!-- #### Report section for a scientific publication -->
<!-- Write a small section for a scientific publication, in which you report the results of the analyses, and explain the conclusions that can be drawn. -->

<!-- ### Bayesian Approach -->

<!-- #### Model description -->

<!-- Describe the mathematical model fitted on the most extensive model. (hint, look at the mark down file of the lectures to see example on formulate mathematical models in markdown). Justify the priors. -->

<!-- #### Model comparison -->

<!-- Conduct model analysis and provide brief interpretation of the results -->

<!-- ```{r} -->
<!-- #include your code and output in the document -->
<!-- ``` -->

<!-- #### Comparison celebrity pair -->

<!-- Compare sentiments of celebrity pairs and provide a brief interpretation (e.g. CIs)  -->


<!-- ## Question 2 - Website visits (between groups - Two factors) -->

<!-- ### Conceptual model -->
<!-- Make a conceptual model underlying this research question -->

<!-- ### Visual inspection -->
<!-- Graphically examine the variation in page visits for different factors levels (e.g. histogram, density plot etc.)  -->


<!-- ```{r} -->
<!-- #include your code and output in the document -->
<!-- ``` -->


<!-- ### Normality check -->
<!-- Visually inspect if variable page visits deviates from a Gaussian distribution, and discuss implication for general linear model analysis. -->


<!-- ```{r} -->
<!-- #include your code and output in the document -->
<!-- ``` -->

<!-- ### Frequentist Approach -->

<!-- #### Model analysis -->
<!-- Conduct a model analysis, to examine the added values of adding 2 factors and interaction between the factors in the model to predict page visits, and include brief interpretation of the results. -->


<!-- ```{r} -->
<!-- #include your code and output in the document -->
<!-- ``` -->


<!-- #### Simple effect analysis -->
<!-- If the analysis shows a significant two-way interaction effect, conduct a Simple Effect analysis to explore this interaction effect in more detail.It helps first to look at the means of different conditions in a figure. Provide brief interpretation of the results. -->


<!-- ```{r} -->
<!-- #include your code and output in the document -->
<!-- ``` -->


<!-- #### Report section for a scientific publication -->
<!-- Write a small section for a scientific publication, in which you report the results of the analyses, and explain the conclusions that can be drawn. -->

<!-- ### Bayesian Approach -->

<!-- #### Model description -->

<!-- Describe the mathematical model fitted on the most extensive model. (hint, look at the mark down file of the lectures to see example on formulate mathematical models in markdown). Justify the priors. -->

<!-- #### Model comparison -->

<!-- Conduct model analysis and provide brief interpretation of the results -->

<!-- ```{r} -->
<!-- #include your code and output in the document -->
<!-- ``` -->



<!-- # Part 3 - Multilevel model -->

<!-- ## Visual inspection -->
<!-- Use graphics to inspect the distribution of the score, and relationship between session and score -->


<!-- ```{r} -->
<!-- #include your code and output in the document -->
<!-- ``` -->

<!-- ## Frequentist approach -->

<!-- ### Multilevel analysis -->
<!-- Conduct multilevel analysis and calculate 95% confidence intervals, determine: -->

<!-- * If session has an impact on people score -->
<!-- * If there is significant variance between the participants in their score -->


<!-- ```{r} -->
<!-- #include your code and output in the document -->
<!-- ``` -->

<!-- ### Report section for a scientific publication -->
<!-- Write a small section for a scientific publication, in which you report the results of the analyses, and explain the conclusions that can be drawn. -->

<!-- ## Bayesian approach -->

<!-- ### Model description -->

<!-- Describe the mathematical model fitted on the most extensive model. (hint, look at the mark down file of the lectures to see example on formulate mathematical models in markdown). Justify the priors. -->

<!-- ### Model comparison -->

<!-- Select the first 100 participants from the data set. (hint to overcome the Stan problem with a zero index, increase subject id number with 1). Compare models with with increasing complexity.  -->

<!-- ```{r} -->
<!-- #include your code and output in the document -->
<!-- ``` -->

<!-- ### Estimates examination -->

<!-- Examine the estimate of parameters of the model with best fitt, and provide a brief interpretation. -->


<!-- ```{r} -->
<!-- #include your code and output in the document -->
<!-- ``` -->


